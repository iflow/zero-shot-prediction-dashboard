{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "<transformers.pipelines.zero_shot_image_classification.ZeroShotImageClassificationPipeline at 0x1ae6ca07100>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import model\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe= pipeline(task= \"zero-shot-image-classification\", model= \"openai/clip-vit-large-patch14-336\")\n",
    "pipe"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'score': 0.3333601653575897, 'label': 'dog'},\n {'score': 0.3081190288066864, 'label': 'lion'},\n {'score': 0.23664647340774536, 'label': 'rabbit'},\n {'score': 0.11083435267210007, 'label': 'cat'},\n {'score': 0.011039966717362404, 'label': 'cheetah'}]"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_to_classify = \"pics/sample0.jpg\"\n",
    "labels_for_classification =  [\"cat\", \"dog\", \"lion\", \"cheetah\", \"rabbit\"]\n",
    "scores = pipe(image_to_classify, candidate_labels = labels_for_classification)\n",
    "scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_26892/1067353633.py, line 56)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  File \u001B[1;32m\"C:\\Users\\WEIGL-~1\\AppData\\Local\\Temp/ipykernel_26892/1067353633.py\"\u001B[1;36m, line \u001B[1;32m56\u001B[0m\n\u001B[1;33m    frequ {'cat': 0.3, 'dog': 0.7}\u001B[0m\n\u001B[1;37m          ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import pandas as pd\n",
    "\n",
    "# Download and return list of sample images\n",
    "# from <https://picsum.photos>\n",
    "def downloadDemopics(n=10):\n",
    "    URL= \"https://picsum.photos/600/600\"\n",
    "\n",
    "    if not os.path.exists('pics/'):\n",
    "        os.mkdir('pics/')\n",
    "\n",
    "    for i in range(n):\n",
    "        torch.hub.download_url_to_file(URL, 'pics/sample{}.jpg'.format(i))\n",
    "\n",
    "    demoPics= ['pics/'+file for file in os.listdir(\"pics\")]\n",
    "    return demoPics\n",
    "\n",
    "# create the WordCloud image\n",
    "def getWorldCloud(frequencies):\n",
    "    wordcloud = WordCloud(width=800, height=600, relative_scaling=0.8, background_color='white')\n",
    "\n",
    "    # generate the word cloud\n",
    "    wordcloud.generate_from_frequencies(frequencies)\n",
    "\n",
    "    #plot\n",
    "    # plt.figure(figsize=(16, 12))\n",
    "    # plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "\n",
    "    # second method with image\n",
    "    image = wordcloud.to_image()\n",
    "    # image.show()\n",
    "    return image\n",
    "\n",
    "# zero-shot-image-classification\n",
    "# pipe= pipeline(task= \"zero-shot-image-classification\", model= \"openai/clip-vit-large-patch14-336\")\n",
    "\n",
    "# model that can do 22k-category classification\n",
    "pipe= pipeline(task= \"image-classification\", model= \"microsoft/beit-base-patch16-224-pt22k-ft22k\")\n",
    "\n",
    "def calc(image_to_classify):\n",
    "\n",
    "    # scores = pipe(image_to_classify= image_to_classify, candidate_labels = labels_for_classification)\n",
    "    scores = pipe(images= image_to_classify)\n",
    "\n",
    "    # transform result\n",
    "    df= pd.DataFrame(scores)\n",
    "    frequ= df[[\"label\", \"score\"]].set_index(\"label\").to_dict()[\"score\"]\n",
    "    image= getWorldCloud(frequ)\n",
    "\n",
    "    return frequ, image\n",
    "\n",
    "# main\n",
    "# if __name__ == '__main__':\n",
    "if True:\n",
    "\n",
    "    # download demo pictures\n",
    "    demoPics= downloadDemopics()\n",
    "\n",
    "    labels= \"cat, dog, lion, cheetah, rabbit\"\n",
    "    examples= [[pic, labels] for pic in demoPics]\n",
    "\n",
    "    demo = gr.Interface(\n",
    "        calc,\n",
    "        # [ # inputs\n",
    "        #     \"image\",\n",
    "        #     \"text\"\n",
    "        # ],\n",
    "        inputs=[gr.Image(type=\"pil\", tool=\"select\", shape=(800,800))],\n",
    "        outputs=[ # outputs\n",
    "            \"label\",\n",
    "            \"image\"\n",
    "        ],\n",
    "        examples= examples,\n",
    "        title= \"Find the things\",\n",
    "        description= \"Please input a picture and a list of labels\",\n",
    "        allow_flagging= \"manual\",\n",
    "        flagging_options= [\"COOL\", \"STRANGE\"]\n",
    "    )\n",
    "\n",
    "    demo.launch()\n",
    "    #demo.launch(server_name='0.0.0.0', server_port=7861)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
